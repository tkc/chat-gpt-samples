{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "d5f777c3",
            "metadata": {},
            "source": [
                "## Azure langchain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ab65b9ae",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.27.0)\n",
                        "Requirement already satisfied: langchain in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.0.157)\n",
                        "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.3.1)\n",
                        "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.7.3)\n",
                        "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (2.28.2)\n",
                        "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.64.1)\n",
                        "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (3.8.3)\n",
                        "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (6.0)\n",
                        "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.4.46)\n",
                        "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (4.0.2)\n",
                        "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.5.7)\n",
                        "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (2.8.4)\n",
                        "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.23.5)\n",
                        "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.2.4)\n",
                        "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.10.4)\n",
                        "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (8.2.2)\n",
                        "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 3)) (2022.10.31)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (22.2.0)\n",
                        "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (2.1.1)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (6.0.4)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.8.2)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.3)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.1)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (3.19.0)\n",
                        "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (1.5.1)\n",
                        "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (0.8.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain->-r requirements.txt (line 2)) (4.5.0)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (3.4)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (1.26.12)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (2022.12.7)\n",
                        "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.3->langchain->-r requirements.txt (line 2)) (2.0.2)\n",
                        "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (23.1)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "5d0efdcc",
            "metadata": {},
            "outputs": [],
            "source": [
                "!export AZURE_API_BASE=https://tresen-test-1.openai.azure.com/\n",
                "!export AZURE_OPEN_API_KEY=2e9de9a9d04c4702823a16e233ebd02c"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "853669ad",
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "'AZURE_API_BASE'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[1;32m/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb Cell 4\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# openai.api_key = os.environ['API_KEY']\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# os.environ[\"OPENAI_API_KEY\"] = os.environ['API_KEY']\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazure\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m  os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mAZURE_API_BASE\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2023-03-15-preview\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/takeshiiijima/github/chat-gpt-samples/018.azure_langchain/azure_langchain.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m  os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mAZURE_OPEN_API_KEY\u001b[39m\u001b[39m'\u001b[39m]\n",
                        "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    680\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'AZURE_API_BASE'"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import openai\n",
                "\n",
                "# openai.api_key = os.environ['API_KEY']\n",
                "# os.environ[\"OPENAI_API_KEY\"] = os.environ['API_KEY']\n",
                "\n",
                "openai.api_type = \"azure\"\n",
                "openai.api_base =  os.environ['AZURE_API_BASE']\n",
                "openai.api_version = \"2023-03-15-preview\"\n",
                "openai.api_key =  os.environ['AZURE_OPEN_API_KEY']\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "9080b39e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index import (\n",
                "    GPTVectorStoreIndex, \n",
                "    GPTSimpleKeywordTableIndex, \n",
                "    SimpleDirectoryReader,\n",
                "    LLMPredictor,\n",
                "    ServiceContext\n",
                ")\n",
                "\n",
                "from langchain.llms.openai import OpenAIChat\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "79809156",
            "metadata": {},
            "outputs": [],
            "source": [
                "wiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "b4b4387b-413e-4016-ba1e-88b3d9410a38",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import requests\n",
                "for title in wiki_titles:\n",
                "    response = requests.get(\n",
                "        'https://en.wikipedia.org/w/api.php',\n",
                "        params={\n",
                "            'action': 'query',\n",
                "            'format': 'json',\n",
                "            'titles': title,\n",
                "            'prop': 'extracts',\n",
                "            # 'exintro': True,\n",
                "            'explaintext': True,\n",
                "        }\n",
                "    ).json()\n",
                "    page = next(iter(response['query']['pages'].values()))\n",
                "    wiki_text = page['extract']\n",
                "\n",
                "    data_path = Path('data')\n",
                "    if not data_path.exists():\n",
                "        Path.mkdir(data_path)\n",
                "\n",
                "    with open(data_path / f\"{title}.txt\", 'w') as fp:\n",
                "        fp.write(wiki_text)\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "482e7744",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load all wiki documents\n",
                "city_docs = {}\n",
                "for wiki_title in wiki_titles:\n",
                "    city_docs[wiki_title] = SimpleDirectoryReader(input_files=[f\"data/{wiki_title}.txt\"]).load_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/site-packages/langchain/llms/openai.py:687: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "# # LLM Predictor (gpt-3.5-turbo)\n",
                "llm_predictor_chatgpt = LLMPredictor(llm=OpenAIChat(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
                "service_context = ServiceContext.from_defaults(\n",
                "    llm_predictor=llm_predictor_chatgpt, chunk_size_limit=1024\n",
                ")\n",
                "\n",
                "# llm_predictor_gpt4 = LLMPredictor(llm=OpenAIChat(temperature=0, model_name=\"gpt-4\"))\n",
                "# service_context = ServiceContext.from_defaults(\n",
                "#     llm_predictor=llm_predictor_gpt4, chunk_size_limit=1024"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "1298bbb4-c99e-431e-93ef-eb32c0a2fc2a",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 20744 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 16942 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 26082 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 18648 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 21844 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                }
            ],
            "source": [
                "# Build city document index\n",
                "vector_indices = {}\n",
                "for wiki_title in wiki_titles:\n",
                "    \n",
                "    # build vector index\n",
                "    vector_indices[wiki_title] = GPTVectorStoreIndex.from_documents(\n",
                "        city_docs[wiki_title], service_context=service_context\n",
                "    )\n",
                "\n",
                "    # set id for vector index\n",
                "    vector_indices[wiki_title].set_index_id(wiki_title)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "0b4fe9b6-5762-4e86-b51e-aac45d3ecdb1",
            "metadata": {},
            "outputs": [],
            "source": [
                "index_summaries = {\n",
                "    wiki_title: (\n",
                "        f\"This content contains Wikipedia articles about {wiki_title}. \"\n",
                "        f\"Use this index if you need to lookup specific facts about {wiki_title}.\\n\"\n",
                "        \"Do not use this index if you want to analyze multiple cities.\"\n",
                "    )\n",
                "    for wiki_title in wiki_titles\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "5eec265d-211b-4f26-b05b-5b4e7072bc6e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1835 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                }
            ],
            "source": [
                "query_engine = vector_indices[\"Toronto\"].as_query_engine()\n",
                "response = query_engine.query(\"What are the sports teams in Toronto?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "68c9ebfe-b1b6-4f4e-9278-174346de8c90",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Toronto is represented in five major league sports, with teams in the National Hockey League (NHL), Major League Baseball (MLB), National Basketball Association (NBA), Canadian Football League (CFL), and Major League Soccer (MLS). The specific teams are the Toronto Maple Leafs, Toronto Blue Jays, Toronto Raptors, Toronto Argonauts, and Toronto FC.\n"
                    ]
                }
            ],
            "source": [
                "print(str(response))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4fc3f18a-0ef9-453c-acf8-7aedd784cdcf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "from llama_index.indices.composability import ComposableGraph\n",
                "\n",
                "graph = ComposableGraph.from_indices(\n",
                "    GPTSimpleKeywordTableIndex,\n",
                "    [index for _, index in vector_indices.items()], \n",
                "    [summary for _, summary in index_summaries.items()],\n",
                "    max_keywords_per_chunk=50\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "97f3ddf1-8dc2-4fb8-831f-2c06649e0955",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get root index\n",
                "root_index = graph.get_index(graph.root_id)\n",
                "\n",
                "# set id of root index\n",
                "root_index.set_index_id(\"compare_contrast\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "2c425a7f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# define decompose_transform\n",
                "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
                "\n",
                "decompose_transform = DecomposeQueryTransform(\n",
                "    llm_predictor_chatgpt, verbose=True\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "53265fd4-da98-4cf9-abfb-3f76105fd2ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# define custom retrievers\n",
                "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
                "\n",
                "custom_query_engines = {}\n",
                "\n",
                "for index in vector_indices.values():\n",
                "    query_engine = index.as_query_engine(service_context=service_context)\n",
                "    query_engine = TransformQueryEngine(\n",
                "        query_engine,\n",
                "        query_transform=decompose_transform,\n",
                "        transform_extra_info={'index_summary': index.index_struct.summary},\n",
                "    )\n",
                "    custom_query_engines[index.index_id] = query_engine\n",
                "\n",
                "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
                "    retriever_mode='simple',\n",
                "    response_mode='tree_summarize',\n",
                "    service_context=service_context,\n",
                "    verbose=True,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "1ed78fdb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# define graph\n",
                "graph_query_engine = graph.as_query_engine(\n",
                "    custom_query_engines=custom_query_engines\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "aaa70744",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.indices.keyword_table.retrievers:> Starting query: Compare and contrast the arts and culture of Houston and Boston. \n",
                        "INFO:llama_index.indices.keyword_table.retrievers:query keywords: ['boston', 'culture', 'compare', 'arts', 'contrast', 'houston']\n",
                        "INFO:llama_index.indices.keyword_table.retrievers:> Extracted keywords: ['boston', 'houston']\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston. \n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Boston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston. \n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Boston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1949 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston. \n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Houston?\n",
                        "\u001b[0m////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston. \n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Houston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1856 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 521 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 521 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                }
            ],
            "source": [
                "query_str = (\n",
                "    \"Compare and contrast the arts and culture of Houston and Boston. \"\n",
                ")\n",
                "response = graph_query_engine.query(query_str)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "affc7faf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Both Houston and Boston have a rich arts and culture scene. Boston is known for its classical music institutions such as Boston Symphony Hall and the Handel and Haydn Society, as well as its museums like the Museum of Fine Arts and the Isabella Stewart Gardner Museum. It also has a vibrant theater scene with venues like the Colonial Theater and the Cutler Majestic Theatre. Boston also hosts events like the Boston Early Music Festival and the Boston Arts Festival.\n",
                        "\n",
                        "Houston, on the other hand, is known for its rodeo and livestock show, as well as its diverse festivals like the Houston Greek Festival and the Art Car Parade. It also has a thriving theater district and museums like the Museum of Fine Arts and the Houston Museum of Natural Science. Houston also has a strong focus on contemporary art with institutions like the Contemporary Arts Museum Houston and the Station Museum of Contemporary Art.\n",
                        "\n",
                        "Overall, while both cities have a strong arts and culture scene, Boston's focus is more on classical music and traditional arts, while Houston has a more diverse range of events and a stronger focus on contemporary art.\n"
                    ]
                }
            ],
            "source": [
                "print(response)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "c3f4752a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index.tools.query_engine import QueryEngineTool\n",
                "\n",
                "query_engine_tools = []\n",
                "\n",
                "# add vector index tools\n",
                "for wiki_title in wiki_titles:\n",
                "    index = vector_indices[wiki_title]\n",
                "    summary = index_summaries[wiki_title]\n",
                "    \n",
                "    query_engine = index.as_query_engine(service_context=service_context)\n",
                "    vector_tool = QueryEngineTool.from_defaults(query_engine, description=summary)\n",
                "    query_engine_tools.append(vector_tool)\n",
                "\n",
                "\n",
                "# add graph tool\n",
                "graph_description = (\n",
                "    \"This tool contains Wikipedia articles about multiple cities. \"\n",
                "    \"Use this tool if you want to compare multiple cities. \"\n",
                ")\n",
                "graph_tool = QueryEngineTool.from_defaults(graph_query_engine, description=graph_description)\n",
                "query_engine_tools.append(graph_tool)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "e6712452",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index.query_engine.router_query_engine import RouterQueryEngine\n",
                "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
                "\n",
                "router_query_engine = RouterQueryEngine(\n",
                "    selector=LLMSingleSelector.from_defaults(service_context=service_context),\n",
                "    query_engine_tools=query_engine_tools\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "acb4e10b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.query_engine.router_query_engine:Selecting query engine 5: This tool contains Wikipedia articles about multiple cities. Use this tool if you want to compare multiple cities..\n",
                        "INFO:llama_index.indices.keyword_table.retrievers:> Starting query: Compare and contrast the arts and culture of Houston and Boston.\n",
                        "INFO:llama_index.indices.keyword_table.retrievers:query keywords: ['boston', 'culture', 'compare', 'arts', 'contrast', 'houston']\n",
                        "INFO:llama_index.indices.keyword_table.retrievers:> Extracted keywords: ['boston', 'houston']\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston.\n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Boston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston.\n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Boston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1949 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston.\n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Houston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n",
                        "////////////\n",
                        "200\n",
                        "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the arts and culture of Houston and Boston.\n",
                        "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What are some notable cultural institutions or events in Houston?\n",
                        "\u001b[0m"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1856 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 459 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 459 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                }
            ],
            "source": [
                "# ask a compare/contrast question \n",
                "response = router_query_engine.query(\n",
                "    \"Compare and contrast the arts and culture of Houston and Boston.\",\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "3536f977",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Houston and Boston both have a rich arts and culture scene. In Boston, notable institutions and events include Boston Symphony Hall, Boston Ballet, Museum of Fine Arts, and the Boston Marathon. Houston also has a diverse range of cultural institutions and events, such as the Houston Livestock Show and Rodeo, Museum of Fine Arts, and the Houston Theater District. Both cities have museums, theaters, and festivals that celebrate their unique cultures. However, Houston has events such as the Houston Greek Festival and the Art Car Parade that are not found in Boston, while Boston has events such as the Boston Early Music Festival and the Italian summer feasts in the North End that are not found in Houston. Overall, both cities offer a vibrant arts and culture scene that is worth exploring.\n"
                    ]
                }
            ],
            "source": [
                "print(response)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "465f2d4f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.query_engine.router_query_engine:Selecting query engine 0: This content contains Wikipedia articles about Toronto. Use this index if you need to lookup specific facts about Toronto. Do not use this index if you want to analyze multiple cities..\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1835 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "////////////\n",
                        "200\n"
                    ]
                }
            ],
            "source": [
                "response = router_query_engine.query(\"What are the sports teams in Toronto?\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "f54954cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Toronto is represented in five major league sports, with teams in the National Hockey League (NHL), Major League Baseball (MLB), National Basketball Association (NBA), Canadian Football League (CFL), and Major League Soccer (MLS). The specific teams are the Toronto Maple Leafs, Toronto Blue Jays, Toronto Raptors, Toronto Argonauts, and Toronto FC.\n"
                    ]
                }
            ],
            "source": [
                "print(response)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
