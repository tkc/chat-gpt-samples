{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 57,
            "id": "ab65b9ae",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: langchain in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (0.0.144)\n",
                        "Requirement already satisfied: llama_index in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (0.5.17.post1)\n",
                        "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.4)\n",
                        "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.5.7)\n",
                        "Requirement already satisfied: requests<3,>=2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.26.0)\n",
                        "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.8.4)\n",
                        "Requirement already satisfied: numpy<2,>=1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.20.3)\n",
                        "Requirement already satisfied: PyYAML>=5.4.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
                        "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
                        "Requirement already satisfied: pydantic<2,>=1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.6)\n",
                        "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
                        "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.22)\n",
                        "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
                        "Requirement already satisfied: pandas in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (1.3.4)\n",
                        "Requirement already satisfied: openai>=0.26.4 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (0.27.2)\n",
                        "Requirement already satisfied: tiktoken in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (0.3.2)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
                        "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
                        "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
                        "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
                        "Requirement already satisfied: packaging>=17.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.0)\n",
                        "Requirement already satisfied: tqdm in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama_index) (4.62.3)\n",
                        "Requirement already satisfied: pyparsing>=2.0.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.4)\n",
                        "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.2)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
                        "Requirement already satisfied: greenlet!=0.4.17 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain) (1.1.1)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
                        "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index) (2.8.2)\n",
                        "Requirement already satisfied: pytz>=2017.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index) (2021.3)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->llama_index) (1.16.0)\n",
                        "Requirement already satisfied: regex>=2022.1.18 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama_index) (2022.10.31)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Requirement already satisfied: llama_index in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (0.5.17.post1)\n",
                        "Requirement already satisfied: langchain in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (0.0.144)\n",
                        "Requirement already satisfied: tiktoken in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (0.3.2)\n",
                        "Requirement already satisfied: dataclasses-json in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (0.5.7)\n",
                        "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (8.2.2)\n",
                        "Requirement already satisfied: openai>=0.26.4 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (0.27.2)\n",
                        "Requirement already satisfied: numpy in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (1.20.3)\n",
                        "Requirement already satisfied: pandas in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from llama_index) (1.3.4)\n",
                        "Requirement already satisfied: PyYAML>=5.4.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
                        "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
                        "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.8.4)\n",
                        "Requirement already satisfied: pydantic<2,>=1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.6)\n",
                        "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.4)\n",
                        "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.22)\n",
                        "Requirement already satisfied: requests<3,>=2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.26.0)\n",
                        "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
                        "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
                        "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama_index) (0.8.0)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama_index) (3.19.0)\n",
                        "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama_index) (1.5.1)\n",
                        "Requirement already satisfied: packaging>=17.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (21.0)\n",
                        "Requirement already satisfied: tqdm in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama_index) (4.62.3)\n",
                        "Requirement already satisfied: pyparsing>=2.0.2 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (3.0.4)\n",
                        "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.2)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
                        "Requirement already satisfied: greenlet!=0.4.17 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain) (1.1.1)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama_index) (0.4.3)\n",
                        "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index) (2.8.2)\n",
                        "Requirement already satisfied: pytz>=2017.3 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index) (2021.3)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->llama_index) (1.16.0)\n",
                        "Requirement already satisfied: regex>=2022.1.18 in /Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama_index) (2022.10.31)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install langchain llama_index\n",
                "%pip install --upgrade llama_index langchain\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "id": "853669ad",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"OPENAI_API_KEY\"] = os.environ['API_KEY']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "id": "9080b39e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<?xml version=\"1.0\" encoding=\"Shift_JIS\"?>\n",
                        "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//EN\"\n",
                        "    \"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\">\n",
                        "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"ja\" >\n",
                        "<head>\n",
                        "\t<meta http-equiv=\"Content-Type\" content=\"text/html;charset=Shift_JIS\" />\n",
                        "\t<meta http-equiv=\"content-style-type\" content=\"text/css\" />\n",
                        "\t<link rel=\"stylesheet\" type=\"text/css\" href=\"../../aozora.css\" />\n",
                        "\t<title>円城塔 鉄道模型の夜</title>\n",
                        "\t<script type=\"text/javascript\" src=\"../../jquery-1.4.2.min.js\"></script>\n",
                        "  <link rel=\"Schema.DC\" href=\"http://purl.org/dc/elements/1.1/\" />\n",
                        "\t<meta name=\"DC.Title\" content=\"鉄道模型の夜\" />\n",
                        "\t<meta name=\"DC.Creator\" content=\"円城塔\" />\n",
                        "\t<meta name=\"DC.Publisher\" content=\"青空文庫\" />\n",
                        "</head>\n",
                        "<body>\n",
                        "<div class=\"metadata\">\n",
                        "<h1 class=\"title\">鉄道模型の夜</h1>\n",
                        "<h2 class=\"author\">円城塔</h2>\n",
                        "<br />\n",
                        "<br />\n",
                        "</div>\n",
                        "<div id=\"contents\" style=\"display:none\"></div><div class=\"main_text\"><br />\n",
                        "　彼の趣味は箱庭であり、鉄道の方はあとからついてきた。だから最初は、小さな庭でも家のミニチュアでも構わなかった。かといって、押絵を風呂敷に包んで旅するような趣味があるわけでなし、縮小するのは持ち運びのためではなかった。旅をするのが面倒なので、宇宙の方をとじこめてしまう。そういう気風が彼にはあった。すなわち、旅をするなら箱庭の中を旅したいのであって、箱庭を持って旅をするなどは本末転倒ということになる。しかし一方、箱庭なるものには息苦しさが伴うのも確かであって、これは箱という制約からくる。とじこめたいが、息はしたいというのが彼の贅沢すぎる悩みである。風景には空気穴がなければならぬ。<br />\n",
                        "　それには、幾筋かの道をつけてやればよい、というのが試行錯誤の末に彼の至った結論であり、右から左へ、あるいは逆に、貫通する何かをおいて気を通わせる。手前から奥では遠近法を強調するようでややあざとい。自動車教習所のような環状の道には徒労感が伴うし、岬の果てや盲腸線といった想像は淀みに通じる。どこからくるかはしらないし、どこへ行くかもわからない。とにかくそこを経由することだけが確かな、切り取られた流れが彼の気性に合ったのである。<br />\n",
                        "　通すものはなんでもよかった。川でも道でも自由だったが、ふと、鉄道という単語が浮かんで、汽車が走り抜けるというのはそれだけで、なんだか箱庭を最後までつくりきることができそうな気持ちにさせるのである。<br />\n",
                        "　そうして彼は、鉄道の走る箱庭を趣味とすることになったわけだが、嵩じて自然に、取材の旅へ出ることとなり、これは彼の頭の容積よりも空の方が広かったという事実に起因していて、つまりは素材に窮してしまった。箱庭の中では汽車だけが確固たる存在感を放ち続けて、彼の中の思い出たちはまるで紙かプラスチックでつくられたように脆弱であり、直角さえもが頼りなくみえたのである。<br />\n",
                        "<br />\n",
                        "　箱庭づくりはこうして彼を箱の外へと誘うことになり、旅をするのが面倒なので箱庭を眺めるつもりの彼は、箱庭の素材を求めて旅へと出掛ける羽目に陥った。そのなりゆきを奇妙とは思ったものの、意外に苦とは感じなかった。カメラを構えて、模型に利用できそうな細部を集める旅は、箱庭の素材を買い出しに出掛けるのと大きく変わるところがないと彼は感じた。カメラについた望遠寄りのレンズもまたその印象を強化した。はじめの頃は広角のレンズを試してみたこともあったのだが、そこに広がるまるで旅先のような光景は彼をひどく当惑させた。それほど大きな広がりは頭の中に入りきりそうにはなかった。<br />\n",
                        "　彼のつくるほんの三十センチ四方程度の箱庭は、写実的などこかの風景というものではなく、あちらこちらから集められてきた細部の集積であり継ぎ接ぎから成り立っている。どこかの町のいつかの一瞬を正確に切り取りたいのなら、正にそのときその場所に立っているしかないのであり、箱庭などつくる必要がない。自然においては、今目の前の天気が晴れならそれを雨にすることはできず、春ならそれは冬ではなく、夜なら今は朝ではない。彼が箱庭を愛する理由はそうした堅苦しさというべきか几帳面さというものなのかを大変苦手としているからであり、あちらは朝でこちらは夜で、そちらは春で、すぐとなりは冬であるというような庭を趣味とした。川の横には道が延び、鉄道がその上へ交差しており、ありえぬ急カーブで曲がっていくようなものを好んだ。<br />\n",
                        "　模型につくると、自然はどうしても間延びしていき、尺をただ縮めただけでは本物らしさが消えていく。であるならばと彼は箱庭にやたらと物を詰め込みはじめ、彼のつくる箱庭はちょっと賑やかな弁当箱のような様相を呈しはじめるのだが、自分の眺める世の中はまさにそのようなものなのだから仕方ないという気持ちがしてきて、世の中が実際にこうであればよいのにと考えてみて、こんなにごちゃごちゃとしていてはかなわないなと同時に彼は考えたりする。<br />\n",
                        "<br />\n",
                        "　片側に迫る山は狭い平地へ急速に下り、その平地には高い側から鉄道と道路、商店街と続いている。さらに下がると横に長い水の広がりがあり、これはおそらく海と思われ、事実瀬戸内海なのであり、その対岸には四国へと飛び石状に続くはずの島の一部が見えている。島にはレモンが植えられており、黄色い実が点々と並ぶ。海には二隻で対のフェリーが一組浮かんで、平地の終わるところから山へはロープウェイが配置され、行方の方は箱庭の天へと消えてうかがいしれない。<br />\n",
                        "　線路は鉄道駅と駅前のバスターミナルに出迎えられて、周囲には会議場やホテルが並び、海沿いの道が現れる。小さく群れる学生の姿や、スーツケースを転がしたり、自転車を押す観光客の姿が現れ、夕食用の買い物帰りの人々と、朝、会社へ向かう人々の流れがすれ違う。夜は東から明け、西に暮れ、フェリーはその境目で、島と陸地を、朝と夕とを結んで行き来している。対岸まではほんの数分の距離であるから、向こうで乗り降りする人数さえも数えられるほどであり、フェリーは着くとすぐ離れ、離れるとまた岸へつき、二隻は互いを追いかけながら巴を描くように見えるのである。<br />\n",
                        "　箱庭の岸には多くのガントリークレーンが並んでおり、浮きドックがその横腹を見せている。大きさとしては駅舎をしのぐそれらの巨大構造物は、まるで気配を消すかのように風景に溶け込んでしまっている。<br />\n",
                        "　もしもそれらの大型機械に注目する者がいたならば、まるで静かな町へ巨大な怪獣たちが襲来してきたというような光景がそこには広がるはずなのだが、箱庭に配置された人々はそんな怪獣たちに気がつくこともなく日常を暮らしているわけであり、今、駅から出て海を眺めている彼は、それをとても不思議なことだと考えていて、ここはなんとしても、怪獣たちを倒す手段をみつけなければと、それには爆弾が必要だろうと考えていて、爆弾といえばレモンであって、レモンといえば爆弾だから、是非ともこの箱庭には、レモンが必要だろうと思うのだが、レモンが木になるなどというのはやはり嘘ではないかと、対岸の島の一部を見ながら考えている。<br />\n",
                        "<br />\n",
                        "　北国生まれの彼にとっては、レモンというのは遠い南の作物で、基本的に輪切りにされて、ソーダや蜂蜜の中に沈められているものなのだった。丸まま一個のレモンがすでに過大であって使いきれる気もしない。<br />\n",
                        "　彼がレモンを求めるのは、桃の季節に水牛のチーズと合わせるためくらいのもので、チーズをちぎり、桃を乱切りにして塩を振る。オリーブ油をまわしかけ、細切りにしたレモンの皮を散らすのである。専用のピーラーを試してみたこともあるのだが、包丁で切った方が好みに合った。レモンの皮に刃を当てて、肉に当たらぬように削ぎ続けると、おおよそ六片くらいがとれる。皮は多目がよいとはいえ、二片もあれば充分であり、さて残りの皮はどうするか、あと二日続けて桃を食べるということだろうか。ところどころ肉をむきだしにして転がるレモンは痛々しく、これを冷蔵庫に放置したなら、干からびるうち凄惨の気を帯びたりもして、正視に耐えない。仕方がないので、<ruby><rb>和蘭芥子</rb><rp>（</rp><rt>クレソン</rt><rp>）</rp></ruby>を買ってくる。ボウルにレモンの果汁を搾り、塩と胡椒、砂糖を適当に振る。粉芥子を溶くかマスタードを落とすかする。和蘭芥子を束のままでねじ切ってあえ、オリーブ油をかけておく。これでようやく一個のレモンを使いきることになるのだが、一仕事という感覚がある。一個でこの有様だから、二つとなれば気が遠くなる。そこに二個のレモンが並んでいたなら、まずは、自分の目を疑いたくなり、次には全てのレモンはただ一つのレモンの別のあらわれなのではないかと考えたりする。<br />\n",
                        "　そのレモンが木になるという。木になることを知ってはいるが、彼の暮らす世界の中でも実際にそういうことが起こるのである。しかも、果樹というのは、どこかおかしいのではないかとこちらが心配になるほどの数、実を結ぶものであるからなおさらのこと、彼には尾道へ向かう動機があったのである。<br />\n",
                        "<br />\n",
                        "　尾道というこの町を彼が取材先に選んだのは第一に緩急を求めたからだ。箱庭における上下の動きは貴重なもので、たとえば１００メートル進む間に<span dir=\"ltr\">10</span>メートル上がる、<span dir=\"ltr\">10</span>％の勾配というのは道としては急なものだが、これを<span dir=\"ltr\">30</span>センチの箱庭に収めるならば、ほんの３センチほどにしかならず、物足りなさが否めない。<br />\n",
                        "　ここで全高<span dir=\"ltr\">30</span>センチを狙うとなれば、縦断勾配は１００％となってしまうから、ほぼ絶壁ということになる。角度にして<span dir=\"ltr\">45</span>度の坂というのは、遠望するにはただの斜面にすぎないが、直面すると本当に垂直な壁なのだとしか思えない。<br />\n",
                        "　その半分、せめて<span dir=\"ltr\">15</span>センチ程度の高さが欲しいとしても、勾配は<span dir=\"ltr\">50</span>％。坂の角度はまだ<span dir=\"ltr\">26</span>度にもなるのであり、それは模型のことだから多少の嘘はつくにせよ、風景を坂道で構成するのは無理そうであり、階段だよりとなることになる。階段ということならばと考えてみて、彼の頭に浮かんだ名前が尾道である。<br />\n",
                        "　第二には、地形の変化が要り用だった。彼の腕では陸ばかりでは間が持ちにくい。海と山を求めるならば、別に神戸でもよいだろうと出掛けたこともあるのだが、何気なく電車で過ぎるぶんには迫って見えた山々なども、いざ箱庭に収めるという目で眺めてみるとどうにも広がりすぎであり、手に負える気がしないのである。六甲山地から淡路島あたりを含む光景を切り取ることも考えたのだが、それは大きな地勢図となり、鉄道模型からはかけ離れてしまうことになりそうだった。<br />\n",
                        "　そうして、これで最後なのだが、瀬戸内という言葉の響きが彼には妙に気になっていて、一度ゆっくり見ておきたいものだという気持ちもあった。それは一体、海であるのか湖なのか、川なのか、という素朴な疑問が浮かぶのである。海であるのは間違いないが、それにしては流れがあると聞いたりもする。北国生まれの彼にとっては、瀬戸内海というのはひどく遠い海であり、オホーツク海や太平洋や日本海よりも遠い海であり、下手をすると地中海よりも遠さを感じる海なのである。須磨のあたりの瀬戸内海は、まだまだ入り口なのではないかという疑いがあった。<br />\n",
                        "<br />\n",
                        "　彼が箱庭の中にとることになる宿は、海沿いにある。かつては倉庫だった場所を改装した形で、二階建てとなっている。何か強い意図があったわけではなくて、検索の結果目についたものを適当に選んだだけである。半分以上は商業施設となっており、レストランが置かれており、バーカウンターが併設される形である。土産物が並んでおり、その並びのままホテルのフロントにつながるのである。<br />\n",
                        "　なにとなく、高層の建物を想像していた彼は携帯端末に表示される地図を見ながら周囲を何度か回りつつ、ホテルらしきものが見あたらないのを奇妙に思うことになるのだが、立ち止まって落ち着いて目をあげたなら、そこにはホテルの入り口があり、なるほど、そういうことであったのかともう一度、倉庫風の建物を眺め直すことになり、するとそこはホテル以外の何物でもなく、今まで自分が何を見ていたものか、過去が急速に拭い去られていくことになる。<br />\n",
                        "　フロントで案内を乞うと二階の部屋の鍵を渡されて、部屋の壁には何か、トロフィーのようなものが突き出ている。ここでいうトロフィーというのは首級で、狩猟の成果の動物の首を剥製にして壁にかけておいたりするあれのことだが、そこにあるのは角だけであり、動物の角ではなくて、自転車のハンドルをかけておくための器材であって、傍には人間はぶら下がらぬようにという意味の注意書きが記されている。<br />\n",
                        "　寝室の向こう側には、壁とガラスで隔てられた水場が見えて、外壁の向こうはすぐに、先ほど彼もスーツケースを引きずりながら歩いてきた海沿いの道となっている様子であって、なるほど、道端の向こうに掘られた世界の裏側の隠れ家に到達したような気分となった。<br />\n",
                        "<br />\n",
                        "　自転車というのはいうまでもなく、尾道の地は、しまなみ街道の起点なのか終点なのか、とにかく瀬戸内の島をつないで、四国は今治まで続く整備された道の端点なのである。車も通るが、自転車も通る。<br />\n",
                        "　自転車が通ることで有名である。全長で<span dir=\"ltr\">60</span>キロほど、島々をつなぐ海上の道が続くことになっている。<br />\n",
                        "　なるほど、この宿はと彼はようやく思い至って、自転車でやってくる客を主に想定して<span class=\"notes\">［＃「想定して」は底本では「想定してて」］</span>いたのかと、スーツケースをゴロゴロと引きずってきた自分の姿が妙に可笑しくなったのであり、それならば自分もと意気込んでから、なにをどうしたものかと考えはじめた。家には確かに、折りたたみ式の小径自転車があるのだったが、それで<span dir=\"ltr\">60</span>キロほどを走り抜けるというのは心許なく、さてそれではロードバイクを一式揃える気が起こるかというとそういうものでもないのであって、では借りるかと考えてみてからようやく、海の上に鉄道はあるまいということに思い至った。今回自分は、鉄道模型を配置するような箱庭の取材にここへとやってきたのであって、高低差を求めてやってきたのである。架空の箱庭のことであるから、海の上、島々を結んで走る鉄道を想像するのも自由だったが、そうするための心の準備は全くできていないのであり、果たして世界のどこかには、主に海の上を走る汽車なるものがあるのかどうかもわからなかった。<br />\n",
                        "　実のところ彼の中では、島を伝って海を渡るという想像自体が育っておらず、並んで浮かぶ鰐の背中を跳んでいく白兎の姿が浮かんだりする程度のもので、鉄道を通せるような強固な土台を海につくれずいるのである。<br />\n",
                        "<br />\n",
                        "　鉄道沿いの道は平坦なのだが、線路を北へ越えると急激に坂が立ち上がり、南へ向かえば商店街と海が広がり、その先には四国へ続く道が延びてゆく。<br />\n",
                        "　彼がまず把握する町の形はそうなっており、これはそのまま箱庭のプランとなっていく。彼は最初に四角い平面を置くのであり、おおまかに海と陸の見当をつける。海岸線に寄り添うように線路を描いて、山陽本線のようなものと考えておく。大宝山への道を散策しながら、箱庭に置く山の高さを考えていく。切り立つ階段を前にして、素直にロープウェイに頼ることにし、海への見晴らしのきく山上へと至る。ロープウェイは、寺の境内にある建物をかすめるような形で進み、町にはすでにあらゆるものが詰め込まれているようでもあって、どうにも自分がつくろうとしているものが先に実現されてしまっているような居心地の悪さを彼は感じて、自分のつくる箱庭では、ロープウェイの行き先を天上にしようと決めることになるのである。<br />\n",
                        "　大宝山からの下り道には、多くの石碑が並べられ、文学のこみちと呼ばれるそこでは、尾道ゆかりの作家や詩人の文章が刻まれていて、栗のような形の大きな岩には、<br />\n",
                        "<br />\n",
                        "<div class=\"jisage_1\" style=\"margin-left: 1em\">\n",
                        "のどかさや<br />\n",
                        "　小山つヽきに<br />\n",
                        "　　　　塔二つ<br />\n",
                        "　　　　　子規<br />\n",
                        "</div>\n",
                        "<br />\n",
                        "　とあり、傍らでは、申し訳程度の屋根をのせた白色の板看板が丁寧に、<br />\n",
                        "<br />\n",
                        "<div class=\"jisage_1\" style=\"margin-left: 1em\">\n",
                        "　正岡子規<br />\n",
                        "のどかさや<br />\n",
                        "　小山つづきに塔二つ<br />\n",
                        "<br />\n",
                        "</div><div class=\"jisage_2\" style=\"margin-left: 2em\">\n",
                        "松山の人、俳誌「ホトトギス」を発刊、俳句革新の大先達となった。<br />\n",
                        "この句は、日清の役に、日本新聞の従軍記者として尾道を通過したときの作で、西国寺の三重塔と天寧寺の海重塔を眺めたものであろう。<br />\n",
                        "</div>\n",
                        "<br />\n",
                        "　と説明を施しており、なるほど、通過したのであるかと思ったりする。通過しただけで刻まれるということならば、この山全体が尾道に多少なりとも関係した文章全ての貯蔵庫のようなものとも思えてきて、どうも箱庭の中に箱庭をつくる男をみつけたような、箱庭の中でそれぞれに勝手な箱庭をつくり続ける人々だらけであるような、しかもその全員が、箱庭の趣旨を丁寧に解説しはじめるような、落ち着かなさが胸の奥から湧きかけるのを呑み込むのである。<br />\n",
                        "<br />\n",
                        "　世に、トマトスキヤキというものがあり、彼はこのレシピを尾道から持ち帰ることになるのだが、別段それをこの町で食べたというわけではなかった。町では店ごとに特徴の異なる尾道ラーメンを繰り返し食べ、オコゼの唐揚げを試してみたくらいにとどまる。海沿いに並ぶ乾物屋で土産などを物色しながら、海鮮が大々的に売り出されていないことに首を傾げ、自転車の客が見込めるだろうに、それらしい軽食処があまり見当たらないことを不思議に思った。<br />\n",
                        "　トマトスキヤキに出会ったのは、林芙美子を検索してみた Wikipedia 上でのことであり、そこには、「昭和<span dir=\"ltr\">23</span>年（１９４８年）の『主婦と生活』６月号」に「林芙美子のトマトのすき焼き」なるものの作り方が書かれていたのだと記されていた。それによると、薄く輪切りにしたトマトを、バターかラードで炒め、火が通ったならば肉を載せ、醤油と甘味料を加えるということである。トマトの旨味と割り下ということだから、試してみるかという気になったが、そのままというのも芸がないから、もう少しレシピを検討してみて、以下のようなものへと至った。<br />\n",
                        "　輪切りにした玉葱を炒めておいて、ついで、好きな形に切ったトマトを投入する。割り下を注ぎ好きなだけ煮て、バジルの葉をどさどさ入れる。溺れかけの玉葱やトマトの上に牛肉を広げ、溶き卵につけて食べる。<br />\n",
                        "　なるほどうまいものだと考えながら、これはハワイで食べるのだというチキンヘッカの牛肉版ではないかと気づき、しかしチキンヘッカにはそれほど何も思うところがなかったという記憶がそこで蘇り、これは牛肉の力というものなのかどうなのか。いや、チキンヘッカは生姜で味つけするのであったかと記憶を探ることになった。<br />\n",
                        "<br />\n",
                        "　尾道で、林芙美子を調べたなりゆきというのはこうである。尾道の商店街の入り口には、傍らの旅行鞄に蝙蝠傘を立てかけしゃがむ、林芙美子像があるのであり、左手は携帯電話を持つかのように顔の横に添えられていて、はてどうしてこんなところに林芙美子が、と旧知に出会ったかのように振る舞うために検索をかけてみたからである。その銅像の手前には、<br />\n",
                        "<br />\n",
                        "<div class=\"jisage_1\" style=\"margin-left: 1em\">\n",
                        "海が見えた<br />\n",
                        "　海が見える<br />\n",
                        "五年振りに見る<br />\n",
                        "尾道の海は<br />\n",
                        "　　なつかしい<br />\n",
                        "　　　林芙美子「放浪記」より<br />\n",
                        "　　　中田貞雄書<br />\n",
                        "</div>\n",
                        "<br />\n",
                        "　という文章が四角い石に刻まれている。なるほどゆかりの人であったか、ということなのだが、林芙美子は『放浪記』を記したとおりに放浪の人生を送った人なのであり、この土地にも各地を転々としたのち、十三歳でやってきた。以来、十九の年に恋人を追い上京するまでを尾道のあたりですごす。尾道時代を思い起こした文章などは貧困に追われる体で、明るい青春なる雰囲気のものではないのだが、その後も尾道へと戻っては文章を書いていたりするわけだから、当人の感覚としては書かれぬものもあったのだろうし、あえて書かなかったものがあったはずだし、書きえぬものがあったのだろうと思われた。<br />\n",
                        "　とはいえ、林芙美子の歩いた道は国内のみにとどまらず、欧州へも及ぶわけだから、石像にはどこか、尾道から林芙美子への片思いを思わせるものがあるのであり、林芙美子にとっては多くの場所のひとつであった尾道が、尾道の側から見ると世界全体へと広がってしまうようなところがある。<br />\n",
                        "　なにか箱庭について大切なことを理解したつもりになって彼はメモを取り出すのだが、何かに気がついたという感覚が残っているだけで、言葉の方は出てこなかった。<br />\n",
                        "<br />\n",
                        "　尾道には、林芙美子と志賀直哉にちなむ建築物が存在する。林芙美子の記念館は新宿区中井にもあり、こちらの方が作家として身が立ったあとの住居であって安定感というものがある。志賀直哉というのも林芙美子とはまた違った意味で旅の人であったから、これは関連施設がどれほどあるのかさえよくわからない。尾道時代に構想がはじまる『暗夜行路』は千葉県我孫子でも書き継がれ、完結するのは奈良の志賀直哉旧居でのことであり、松江では志賀直哉が滞在した家にまた芥川龍之介がすごすということなども起こって、エピソードを拾って歩くだけでも大ごととなる。<br />\n",
                        "　記念館といえば建物だからまだしもとして、人物の像というのはひそかに増殖をするものであり、そういえば鹿児島へ取材へ行ったときにも林芙美子に出会ったような記憶がようやく蘇り、あちらは立ち姿であったのではないかと思う。なぜ鹿児島にというのは、林芙美子の本籍地がそこにあり、母親の故郷であったとかなにかそういう理由であったはずである。近くには少女時代の林芙美子像が腰かけていて、異なる時代の同一人物の像が同じところに並ぶということが、当然のようにそこでは起こっていたのであり、彼を不安にさせたのである。<br />\n",
                        "　どうしても各個の像がそこから独自に生活を開始していくという情景が浮かび、一人の作家の人生が次々と分岐をしては同じような人生をまた繰り返すという不幸がそこで増殖してしまう。なぜなら像をつくられるような作家は作家として死んだ人物であり、別の人生とは言い条、あるときふと作家をやめたりはできないわけで、あくまでも作家の枠にとらわれてしまいそうだからである。像になることのない人間の生はわざわざ分岐などせずとも自由で、時間の中を好きな方へ歩いていけばよいだけなのだが、像は複製だってきくうえに、全く異なる像同士が同一人物であるという奇妙な事態が生じ得て、取材のあとには箱庭へ、小さな人影を多数配置することになる彼としては様々思うことがあるわけなのだが、町の並びに現れた「パン屋航路」の看板に物思いも吹き飛んでしまい、それはなにかと問われても、パン屋以外のなにものでもない。<br />\n",
                        "<br />\n",
                        "　これはのちに彼が家族と、トマトスキヤキをつついているときに判明した話なのだが、自転車乗りという人々には、決まった食事の取り方というものがあるらしい。日に１００キロを走るというような人々の間にあっては、ここで止まってジュースを一杯、あちらで止まって唐揚げをというような栄養補給はもっての外で、適度に水分を補給しつつ決められた燃料を消費していくというストイックさが必要らしい。自転車乗りの本分は自転車に乗り続けることにあり、観光にうつつを抜かすことにはないのである。明日どれだけ走ることができるかをかけ、早目に就寝することになり、陽が昇る頃、その姿はすでに車上だ。なるほどすると、自転車乗りたちが集う盛り場というようなものは形成されにくそうに聞こえてくる。<br />\n",
                        "　実際、レモンを求めて島を歩き続けてみても、特に自転車宿とでも呼ぶべきものは見当たらず、島をひとつひとつ巡りつつ美味いものを食べ歩くというようなスタイルはあまり想定されていないようである。<br />\n",
                        "　彼が尾道を取材先に選んだ理由に、レモンの一大生産地であるというものがあるのは先にも触れたが、これは主に島で生産されているものらしく、駅前のフェリー乗り場から、瀬戸田を目指すことにした。島へ降りれば一面のレモン畑、ということはなく、適当に見当をつけて歩きはじめると、様々の柑橘類の低木が現れるのだが、彼にはそれらの区別がつかない。実際のところ、当の柑橘たち自身にも区別がついているのか彼はやや疑いを抱いているのであり、こう近くに多種が混ざって植えられていると、やがて一様なものになってしまうのではないかと思ったりする。それでも島の地域によってどの柑橘が優勢かという区分は存在するらしく、レモンの地域は<ruby><rb>生口島</rb><rp>（</rp><rt>いくちじま</rt><rp>）</rp></ruby>ということになるようなのだが、なかなかその姿は見えないのである。レモンを求めて島を歩いているうちに、やはり旅は箱庭の中でするものだと彼は思って、自分のつくる箱庭では、レモンを駅の近くとまでは言わずとも、対岸の島あたりに植えようと思う。<br />\n",
                        "<br />\n",
                        "　彼の撮った写真の中では、<br />\n",
                        "<br />\n",
                        "<div class=\"jisage_2\" style=\"margin-left: 2em\">\n",
                        "尾道駅構内221K508M<br />\n",
                        "持光寺前踏切<br />\n",
                        "連絡先　岡山電気指令信通指令室<br />\n",
                        "</div>\n",
                        "<br />\n",
                        "　と横書きされた白い看板が踏切の信号の下にあり、線路を越えた道はすぐさま階段へ続いている。そのあとにも、「一里塚地下道」、「東今の２踏切」、「千光寺前踏切」などなどが続く。千光寺前踏切では、まず階段をのぼって線路と同じ高さまで行き、線路を越えてまた階段をのぼるという道筋になる。歩道橋で越えるつくりもあれば、線路の下をくぐる配置もあって、目線と線路の高さが同じになり、向こうへ海が見えるということなども起こる。<br />\n",
                        "　久保八幡神社では、参道入り口の鳥居を抜けて進むとまず、大通りにでくわすことになるのであり、そこから階段をのぼった先には踏切があり、線路を横切った向こうにまた鳥居があって本殿があるという構成になる。鳥居の向こうへ踏切が見え、また鳥居が立ち、本殿までを見通すという構図となって、これは彼の箱庭に取り入れられている。<br />\n",
                        "　八朔入りの大福などを買い求め、食べ歩く彼のすぐ前を、ジーンズにトレーナー姿でカメラをたすき掛けした男が歩いていくのを彼は見つめて、果たして以前に、こうして自分の背中をまじまじと見つめたことがあったかなと彼は考え、それが取材中の自分であることには、疑いさえも浮かばない。あれが数時間前の自分であるのか、数時間後の自分であるのかは、まあ些細な問題だといえ、今こうして歩くこの町には、この自分と同じ姿の自分がたくさん歩き回っているのだろうと思う。そのあとについて歩いていくと、むこうの自分は夜の海辺にたどり着いており、無造作に柵を越えると、そのまま海へと飛び降りてしまう。水は彼を受け入れず、向こうの自分は平気な様子でそのまま海面を歩いていくのだ。<br />\n",
                        "<br />\n",
                        "　のちに彼のつくることになる箱庭の山は美しく桜に彩られ、対岸にはレモンの黄色が鮮やかで、瀬戸内海の東側では陽が暮れはじめ、西側では夜が明けかけており、海は朝からその朝へと続く夜へと向かって流れていく。箱庭の中に夜が訪れ、そこには、携帯電話での通話を終えて、蝙蝠傘と鞄を提げて立ち上がり、駅舎へ向かう林芙美子像の姿がある。出て行かせるのはまずいかとも思ったのだが、彼女はまたここへ帰ってくるに決まっているのだと思い直した。<br />\n",
                        "　箱庭には町を歩き回る数人の志賀直哉も配置されていて、その全員が街角でパンを買い求め、自作のタイトルを『パン屋航路』に改めようかと考えている。<br />\n",
                        "　波止場には海へと向けて駆け出している少年があり、その手にはレモンが握られている。彼は、港のクレーンを巨大怪獣とみなして、爆弾を投げつけようとしているところだ。<br />\n",
                        "　そうして彼は、レジンで作った海の上へとミニチュアの彼の姿を置いて、これで辻褄は合ったのだろうかと少し考える。辻褄を合わせたからなんなのだと可笑しくなって笑い出す。<br />\n",
                        "　彼は箱庭の線路の上へ、箱庭の果てから夜汽車を送り、林芙美子がその客車へと、一人乗り込む姿を想像している。<br />\n",
                        "<div class=\"chitsuki_0\" style=\"text-align:right; margin-right: 0em\">（了）</div>\n",
                        "<br />\n",
                        "<br />\n",
                        "<br />\n",
                        "</div>\n",
                        "<div class=\"bibliographical_information\">\n",
                        "<hr />\n",
                        "<br />\n",
                        "底本：「すばる　第41巻第6号」集英社<br />\n",
                        "　　　2019（令和元）年5月6日<br />\n",
                        "初出：「すばる　第41巻第6号」集英社<br />\n",
                        "　　　2019（令和元）年5月6日<br />\n",
                        "※誤植を疑った箇所を、著者の指示により、あらためました。<br />\n",
                        "入力：福永信<br />\n",
                        "校正：大久保ゆう<br />\n",
                        "2022年1月2日作成<br />\n",
                        "青空文庫収録ファイル：<br />\n",
                        "このファイルは、著作権者自らの意思により、インターネットの図書館、青空文庫（https://www.aozora.gr.jp/）に収録されています。<br />\n",
                        "<br />\n",
                        "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.ja\"><img alt=\"クリエイティブ・コモンズ・ライセンス\" style=\"border-width:0\" src=\"https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png\" /></a><br />\n",
                        "この作品は、クリエイティブ・コモンズ「表示 - 非営利 - 改変禁止 4.0 国際」でライセンスされています。利用条件は、<a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.ja\">https://creativecommons.org/licenses/by-nc-nd/4.0/deed.ja</a> を参照してください。<br />\n",
                        "<br />\n",
                        "<br />\n",
                        "</div>\n",
                        "<div class=\"notation_notes\">\n",
                        "<hr />\n",
                        "<br />\n",
                        "●表記について<br />\n",
                        "<ul>\n",
                        "\t<li>このファイルは W3C 勧告 XHTML1.1 にそった形式で作成されています。</li>\n",
                        "\t<li>［＃…］は、入力者による注を表す記号です。</li>\n",
                        "</ul>\n",
                        "</div>\n",
                        "<div id=\"card\">\n",
                        "<hr />\n",
                        "<br />\n",
                        "<a href=\"JavaScript:goLibCard();\" id=\"goAZLibCard\">●図書カード</a><script type=\"text/javascript\" src=\"../../contents.js\"></script>\n",
                        "<script type=\"text/javascript\" src=\"../../golibcard.js\"></script>\n",
                        "</div></body>\n",
                        "</html>\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import requests\n",
                "\n",
                "url = 'https://raw.githubusercontent.com/aozorabunko/aozorabunko/master/cards/001916/files/61171_74826.html'\n",
                "res = requests.get(url)\n",
                "res.encoding = res.apparent_encoding\n",
                "text = res.text\n",
                "\n",
                "print(text)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "id": "9d68a2ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./data/61171_74826.html', 'w', encoding='utf-8') as f:\n",
                "     f.write(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "id": "b4b4387b-413e-4016-ba1e-88b3d9410a38",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index import download_loader, GPTSimpleVectorIndex\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "id": "3a3768af",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to\n",
                        "[nltk_data]     /Users/takeshiiijima/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n",
                        "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
                        "[nltk_data]     /Users/takeshiiijima/nltk_data...\n",
                        "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
                        "[nltk_data]       date!\n",
                        "INFO:unstructured:Reading document from string ...\n",
                        "INFO:unstructured:Reading document ...\n"
                    ]
                }
            ],
            "source": [
                "loader = UnstructuredReader()\n",
                "documents = loader.load_data(file=Path(f'./data/61171_74826.html'), \n",
                "                            #  split_documents=False\n",
                "                            )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "id": "6928f42e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Document(text='', doc_id='f107b6b0-14f8-4892-b662-4df91335796a', embedding=None, doc_hash='dc937b59892604f5a86ac96936cd7ff09e25f18ae6b758e8014a24c7fa039e91', extra_info=None)]"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "documents\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "id": "1298bbb4-c99e-431e-93ef-eb32c0a2fc2a",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['OPENAI_API_KEY'] =  os.environ['API_KEY']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "id": "4dea2637",
            "metadata": {},
            "outputs": [],
            "source": [
                "from gpt_index import GPTTreeIndex, SimpleDirectoryReader, LLMPredictor, GPTSimpleVectorIndex, GPTListIndex, Prompt, ServiceContext\n",
                "from gpt_index.indices.base import BaseGPTIndex\n",
                "from gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
                "from langchain.chat_models import ChatOpenAI\n",
                "from langchain.llms import OpenAI\n",
                "from gpt_index.response.schema import Response\n",
                "import pandas as pd\n",
                "from typing import Tuple\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "daae913b",
            "metadata": {},
            "source": [
                "Setup benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "id": "04fe11c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass\n",
                "from typing import List"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "id": "ebaae726",
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class TestCase:\n",
                "    query: str \n",
                "    must_contain: List[str]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "id": "ba7e7f16",
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class TestOutcome:\n",
                "    test: TestCase\n",
                "    response: Response\n",
                "    \n",
                "    @property\n",
                "    def is_correct_response(self) -> bool:\n",
                "        is_correct = True\n",
                "        for answer in self.test.must_contain:\n",
                "            if answer not in self.response.response:\n",
                "                is_correct = False\n",
                "        return is_correct\n",
                "    \n",
                "    @property\n",
                "    def is_correct_source(self) -> bool:\n",
                "        is_correct = True\n",
                "        for answer in self.test.must_contain:\n",
                "            if all(answer not in node.source_text for node in self.response.source_nodes):\n",
                "                is_correct = False\n",
                "        return is_correct"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "id": "6c930569",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Benchmark:\n",
                "    def __init__(self, tests: List[TestCase]) -> None:\n",
                "        self._tests = tests\n",
                "    \n",
                "    def test(self, index: BaseGPTIndex, llm_predictor: LLMPredictor, **kwargs) -> List[TestOutcome]:\n",
                "        outcomes: List[TestOutcome] = []\n",
                "        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
                "        for test in self._tests:\n",
                "            response = index.query(\n",
                "                test.query,\n",
                "                service_context=service_context,\n",
                "                **kwargs\n",
                "            )\n",
                "            outcome = TestOutcome(test=test, response=response)\n",
                "            outcomes.append(outcome)\n",
                "        return outcomes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "id": "ed5587c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_outcome(outcomes: List[TestOutcome]) -> None:\n",
                "    rows = []\n",
                "    for outcome in outcomes:\n",
                "        row = [outcome.test.query, outcome.is_correct_response, outcome.is_correct_source]\n",
                "        rows.append(row)\n",
                "    df = pd.DataFrame(rows, columns=['Test Query', 'Correct Response', 'Correct Source'])\n",
                "    return df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "id": "a2944cd3",
            "metadata": {},
            "outputs": [],
            "source": [
                "test_shumi = TestCase(\n",
                "    query=\"彼の趣味はなんですか？\",\n",
                "    must_contain=[\"箱庭\"]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "id": "19cd04f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "bm = Benchmark([test_shumi])\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "023043e3",
            "metadata": {},
            "source": [
                "LLM based evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "id": "876aa7cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "from gpt_index.prompts.prompt_type import PromptType\n",
                "\n",
                "EVAL_PROMPT_TMPL = (\n",
                "    \"Given the question below. \\n\"\n",
                "    \"---------------------\\n\"\n",
                "    \"{query_str}\"\n",
                "    \"\\n---------------------\\n\"\n",
                "    \"Decide if the following retreived context is relevant. \\n\"\n",
                "    \"\\n---------------------\\n\"\n",
                "    \"{context_str}\"\n",
                "    \"\\n---------------------\\n\"\n",
                "    \"Then decide if the answer is correct. \\n\"\n",
                "    \"\\n---------------------\\n\"\n",
                "    \"{answer_str}\"\n",
                "    \"\\n---------------------\\n\"\n",
                "    \"Answer in the following format:\\n\"\n",
                "    \"'Context is relevant: <True>\\nAnswer is correct: <True>' \"\n",
                "    \"and explain why.\"\n",
                ")\n",
                "\n",
                "class EvalPrompt(Prompt):\n",
                "    prompt_type: PromptType = PromptType.CUSTOM\n",
                "    input_variables: List[str] = [\"query_str\", 'context_str', 'answer_str']\n",
                "\n",
                "DEFAULT_EVAL_PROMPT = EvalPrompt(EVAL_PROMPT_TMPL)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "id": "be7c8524",
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "def extract_eval_result(result_str: str):\n",
                "    boolean_pattern = r\"(True|False)\"\n",
                "    matches = re.findall(boolean_pattern, result_str)\n",
                "    return [match == \"True\" for match in matches]  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "192f185e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_outcome_llm_single(outcome: TestOutcome, llm_predictor: LLMPredictor) -> Tuple[bool, bool]:\n",
                "    try:\n",
                "        source_text = outcome.response.source_nodes[0].source_text\n",
                "    except:\n",
                "        source_text = \"Failed to retrieve any context\"\n",
                "        \n",
                "    result_str, _ = llm_predictor.predict(\n",
                "        DEFAULT_EVAL_PROMPT,\n",
                "        query_str=outcome.test.query,\n",
                "        context_str=source_text,\n",
                "        answer_str=outcome.response.response\n",
                "    )\n",
                " \n",
                "    is_context_relevant, is_answer_correct = extract_eval_result(result_str)\n",
                "    return is_answer_correct, is_context_relevant, result_str"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "id": "671d1832",
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_outcome_llm(outcomes: List[TestOutcome], llm_predictor: LLMPredictor) -> None:\n",
                "    rows = []\n",
                "    for outcome in outcomes:\n",
                "        is_correct_response, is_correct_source, result_str = analyze_outcome_llm_single(outcome, llm_predictor)\n",
                "        row = [outcome.test.query, is_correct_response, is_correct_source, result_str]\n",
                "        rows.append(row)\n",
                "    df = pd.DataFrame(rows, columns=['Test Query', 'Correct Response (LLM)', 'Correct Source (LLM)', 'Eval (LLM)'])\n",
                "    return df\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "6bf67fe6",
            "metadata": {},
            "source": [
                "Build Indices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "id": "03f2373e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "vector_index = GPTSimpleVectorIndex.from_documents(documents)\n",
                "list_index = GPTListIndex.from_documents(documents)\n",
                "tree_index = GPTTreeIndex.from_documents(documents)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "id": "4d441575",
            "metadata": {},
            "outputs": [],
            "source": [
                "vector_index.save_to_disk('vector_index.json')\n",
                "tree_index.save_to_disk('tree_index.json')\n",
                "list_index.save_to_disk('list_index.json')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "id": "fcc5c944",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load indices\n",
                "tree_index = GPTTreeIndex.load_from_disk('tree_index.json')\n",
                "list_index = GPTListIndex.load_from_disk('list_index.json')\n",
                "vector_index = GPTSimpleVectorIndex.load_from_disk('vector_index.json')\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ba986b85",
            "metadata": {},
            "source": [
                "Create LLMPredictors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "id": "84d8c5a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# gpt-4\n",
                "llm_predictor_gpt4 = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n",
                "# gpt-3 (text-davinci-003)\n",
                "llm_predictor_gpt3 = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
                "# chatgpt (gpt-3.5-turbo)\n",
                "llm_predictor_chatgpt = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "53fb72df",
            "metadata": {},
            "source": [
                "Benchmarking"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "id": "02e55490",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.indices.tree.leaf_query:> Starting query: 彼の趣味はなんですか？\n"
                    ]
                },
                {
                    "ename": "ZeroDivisionError",
                    "evalue": "integer division or modulo by zero",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/759622253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutcomes_tree_gpt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_predictor_gpt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3049098462.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, index, llm_predictor, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mservice_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_predictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_predictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             response = index.query(\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mservice_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0muse_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_async\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     async def aquery(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_runner.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str_or_bundle, index_id, level)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mquery_str_or_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         )\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_combiner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     async def aquery(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_combiner/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query_bundle, level)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"\"\"Run query combiner.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mupdated_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         return self._query_runner.query_transformed(\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mupdated_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_runner.py\u001b[0m in \u001b[0;36mquery_transformed\u001b[0;34m(self, query_bundle, index_struct, level)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mquery_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     def _fetch_recursive_nodes(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/token_counter/token_counter.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_llm_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwrapper_logic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_return_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;34m\"\"\"Answer a query.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# TODO: support include summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mllm_token_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/tree/leaf_query.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mprint_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         response_str = self._query_level(\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/tree/leaf_query.py\u001b[0m in \u001b[0;36m_query_level\u001b[0;34m(self, cur_node_ids, query_bundle, level)\u001b[0m\n\u001b[1;32m    140\u001b[0m             )\n\u001b[1;32m    141\u001b[0m             numbered_node_text = (\n\u001b[0;32m--> 142\u001b[0;31m                 self._service_context.prompt_helper.get_numbered_text_from_nodes(\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0mcur_node_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_numbered_text_from_nodes\u001b[0;34m(self, node_list, prompt)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# add padding given the number, and the newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             text_splitter = self.get_text_splitter_given_prompt(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_text_splitter_given_prompt\u001b[0;34m(self, prompt, num_chunks, padding)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# generate empty_prompt_txt to compute initial tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mempty_prompt_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_empty_prompt_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         chunk_size = self.get_chunk_size_given_prompt(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mempty_prompt_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_chunk_size_given_prompt\u001b[0;34m(self, prompt_text, num_chunks, padding)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# NOTE: if embedding limit is specified, then chunk_size must not be larger than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# embedding_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         result = (\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_input_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnum_prompt_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         ) // num_chunks\n",
                        "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
                    ]
                }
            ],
            "source": [
                "outcomes_tree_gpt4 = bm.test(tree_index, llm_predictor_gpt4)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3dfc82c6",
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "argument of type 'NoneType' is not iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/1269457722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes_tree_gpt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3409068865.py\u001b[0m in \u001b[0;36manalyze_outcome\u001b[0;34m(outcomes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test Query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Response'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/814219922.py\u001b[0m in \u001b[0;36mis_correct_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_contain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
                    ]
                }
            ],
            "source": [
                "analyze_outcome(outcomes_tree_gpt4)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd34d9a5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.indices.tree.leaf_query:> Starting query: 彼の趣味はなんですか？\n"
                    ]
                },
                {
                    "ename": "ZeroDivisionError",
                    "evalue": "integer division or modulo by zero",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/85766972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutcomes_tree_gpt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_predictor_gpt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3049098462.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, index, llm_predictor, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mservice_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_predictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_predictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             response = index.query(\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mservice_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0muse_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_async\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     async def aquery(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_runner.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str_or_bundle, index_id, level)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mquery_str_or_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         )\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_combiner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     async def aquery(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_combiner/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query_bundle, level)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"\"\"Run query combiner.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mupdated_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         return self._query_runner.query_transformed(\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mupdated_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_runner.py\u001b[0m in \u001b[0;36mquery_transformed\u001b[0;34m(self, query_bundle, index_struct, level)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mquery_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     def _fetch_recursive_nodes(\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/token_counter/token_counter.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_llm_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwrapper_logic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_return_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;34m\"\"\"Answer a query.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# TODO: support include summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mllm_token_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/tree/leaf_query.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mprint_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         response_str = self._query_level(\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/tree/leaf_query.py\u001b[0m in \u001b[0;36m_query_level\u001b[0;34m(self, cur_node_ids, query_bundle, level)\u001b[0m\n\u001b[1;32m    140\u001b[0m             )\n\u001b[1;32m    141\u001b[0m             numbered_node_text = (\n\u001b[0;32m--> 142\u001b[0;31m                 self._service_context.prompt_helper.get_numbered_text_from_nodes(\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0mcur_node_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_numbered_text_from_nodes\u001b[0;34m(self, node_list, prompt)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# add padding given the number, and the newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             text_splitter = self.get_text_splitter_given_prompt(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_text_splitter_given_prompt\u001b[0;34m(self, prompt, num_chunks, padding)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# generate empty_prompt_txt to compute initial tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mempty_prompt_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_empty_prompt_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         chunk_size = self.get_chunk_size_given_prompt(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mempty_prompt_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/prompt_helper.py\u001b[0m in \u001b[0;36mget_chunk_size_given_prompt\u001b[0;34m(self, prompt_text, num_chunks, padding)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# NOTE: if embedding limit is specified, then chunk_size must not be larger than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# embedding_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         result = (\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_input_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnum_prompt_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         ) // num_chunks\n",
                        "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
                    ]
                }
            ],
            "source": [
                "outcomes_tree_gpt3 = bm.test(tree_index, llm_predictor_gpt3)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5623d88",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'outcomes_tree_gpt3' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/1118397189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes_tree_gpt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'outcomes_tree_gpt3' is not defined"
                    ]
                }
            ],
            "source": [
                "analyze_outcome(outcomes_tree_gpt3)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9a5cf01e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
                    ]
                }
            ],
            "source": [
                "outcomes_vector_gpt4 = bm.test(vector_index, llm_predictor_gpt4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fbab7f8b",
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "argument of type 'NoneType' is not iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/2766341985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes_vector_gpt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3409068865.py\u001b[0m in \u001b[0;36manalyze_outcome\u001b[0;34m(outcomes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test Query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Response'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/814219922.py\u001b[0m in \u001b[0;36mis_correct_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_contain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
                    ]
                }
            ],
            "source": [
                "analyze_outcome(outcomes_vector_gpt4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4b9ee1c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
                    ]
                }
            ],
            "source": [
                "outcomes_vector_gpt3 = bm.test(vector_index, llm_predictor_gpt3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "026b7612",
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "argument of type 'NoneType' is not iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/987863868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes_vector_gpt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3409068865.py\u001b[0m in \u001b[0;36manalyze_outcome\u001b[0;34m(outcomes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test Query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Response'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/814219922.py\u001b[0m in \u001b[0;36mis_correct_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_contain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
                    ]
                }
            ],
            "source": [
                "analyze_outcome(outcomes_vector_gpt3)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1757bf7f",
            "metadata": {},
            "source": [
                "LLM based Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e6e92cc",
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "argument of type 'NoneType' is not iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/987863868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes_vector_gpt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/3409068865.py\u001b[0m in \u001b[0;36manalyze_outcome\u001b[0;34m(outcomes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_correct_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test Query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Response'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/var/folders/27/6hk2mfzs5vv9ysvns0ydhx2m0000gn/T/ipykernel_23070/814219922.py\u001b[0m in \u001b[0;36mis_correct_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_contain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
                    ]
                }
            ],
            "source": [
                "analyze_outcome(outcomes_vector_gpt3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "be49fe32",
            "metadata": {},
            "outputs": [],
            "source": [
                "eval_gpt4 = analyze_outcome_llm(outcomes_vector_gpt3, llm_predictor_gpt4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0127d400",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Test Query</th>\n",
                            "      <th>Correct Response (LLM)</th>\n",
                            "      <th>Correct Source (LLM)</th>\n",
                            "      <th>Eval (LLM)</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>彼の趣味はなんですか？</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>Context is relevant: True\\nAnswer is correct: ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    Test Query  Correct Response (LLM)  Correct Source (LLM)  \\\n",
                            "0  彼の趣味はなんですか？                    True                  True   \n",
                            "\n",
                            "                                          Eval (LLM)  \n",
                            "0  Context is relevant: True\\nAnswer is correct: ...  "
                        ]
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "eval_gpt4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5bfa8f6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/takeshiiijima/opt/anaconda3/lib/python3.9/site-packages/gpt_index/data_structs/node_v2.py:144: UserWarning: .source_text is deprecated, use .node.get_text() instead\n",
                        "  warnings.warn(\".source_text is deprecated, use .node.get_text() instead\")\n"
                    ]
                }
            ],
            "source": [
                "eval_chatgpt = analyze_outcome_llm(outcomes_vector_gpt3, llm_predictor_chatgpt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7aa38f96",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Test Query</th>\n",
                            "      <th>Correct Response (LLM)</th>\n",
                            "      <th>Correct Source (LLM)</th>\n",
                            "      <th>Eval (LLM)</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>彼の趣味はなんですか？</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>Context is relevant: True\\nAnswer is correct: ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    Test Query  Correct Response (LLM)  Correct Source (LLM)  \\\n",
                            "0  彼の趣味はなんですか？                    True                  True   \n",
                            "\n",
                            "                                          Eval (LLM)  \n",
                            "0  Context is relevant: True\\nAnswer is correct: ...  "
                        ]
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "eval_chatgpt"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
