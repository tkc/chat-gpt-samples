{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OqrgIY5Ub2gV",
        "outputId": "37d0b405-e08b-4052-d17c-c0d94eb39548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/site-packages (0.0.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain) (1.10.4)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.10/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain) (8.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (0.26.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/site-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain\n",
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain import OpenAI, ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwCn8Nj25Rbs",
        "outputId": "7e240160-7eb3-41bc-84ba-9127ae339add"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "openai.api_key = os.environ['API_KEY']\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ['API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K02-maUUdVXG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' はい。ブロックチェーンの専門家として、私は、データを安全に複数のノードで保存し、共有データを安全にストアするために、暗号化手法を使用するということを理解しています。また、インターネット上で安全なデータ転送を行うために、ブロックチェーン上のすべてのノード間で信頼的なテクノロジーを実装する方法を熟知しています。'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.9, \n",
        "               model_name=\"text-davinci-003\", \n",
        "               max_tokens=2000),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "conversation.predict(input=\"ブロックチェーンの専門家として答えてください。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t96wTq97mFzf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい。ブロックチェーンの専門家として、私は、データを安全に複数のノードで保存し、共有データを安全にストアするために、暗号化手法を使用するということを理解しています。また、インターネット上で安全なデータ転送を行うために、ブロックチェーン上のすべてのノード間で信頼的なテクノロジーを実装する方法を熟知しています。\n",
            "Human: web3の未来を4つの要点にまとめてください。\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "answer =conversation.predict_and_parse(input=\"web3の未来を4つの要点にまとめてください。\")\n",
        "res = {\"total\":answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい。ブロックチェーンの専門家として、私は、データを安全に複数のノードで保存し、共有データを安全にストアするために、暗号化手法を使用するということを理解しています。また、インターネット上で安全なデータ転送を行うために、ブロックチェーン上のすべてのノード間で信頼的なテクノロジーを実装する方法を熟知しています。\n",
            "Human: web3の未来を4つの要点にまとめてください。\n",
            "AI:  Web3の未来を4つの要点にまとめると次のようになります。1つ目は、参加者間でより適切な信頼を得ることで、ビジネスプロセスを安全かつ効率的に行えるようになることです。2つ目は、ブロックチェーンを利用すると、ビジネスプロセスの複雑さが非常に減少することです。3つ目は、データを暗号化して、ストレージを拡張することで、損失のない情報管理を行えるようになることです。4つ目は、参加者間でのコストを低減するための、インターネット上での仲介行為をスケーリングすることです。\n",
            "Human: 1めの要点を300文字程度でまとめてください。\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "answer =conversation.predict_and_parse(input=\"1めの要点を300文字程度でまとめてください。\")\n",
        "res = {\"1\":answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOs54K04hUjL",
        "outputId": "ae60b136-811e-4c87-a147-8ec5160f21b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい。ブロックチェーンの専門家として、私は、データを安全に複数のノードで保存し、共有データを安全にストアするために、暗号化手法を使用するということを理解しています。また、インターネット上で安全なデータ転送を行うために、ブロックチェーン上のすべてのノード間で信頼的なテクノロジーを実装する方法を熟知しています。\n",
            "Human: web3の未来を4つの要点にまとめてください。\n",
            "AI:  Web3の未来を4つの要点にまとめると次のようになります。1つ目は、参加者間でより適切な信頼を得ることで、ビジネスプロセスを安全かつ効率的に行えるようになることです。2つ目は、ブロックチェーンを利用すると、ビジネスプロセスの複雑さが非常に減少することです。3つ目は、データを暗号化して、ストレージを拡張することで、損失のない情報管理を行えるようになることです。4つ目は、参加者間でのコストを低減するための、インターネット上での仲介行為をスケーリングすることです。\n",
            "Human: 1めの要点を300文字程度でまとめてください。\n",
            "AI:  第1の要点は、参加者間の関係に基づいて、より適切な信頼を得ることで、ビジネスプロセスを安全かつ効率的に行えるようにすることです。ブロックチェーンを利用すると、特定のプロセスをより迅速かつ安全に行えるようになります。また、プライバシー、安全性、可用性などの要件を満たすために、データを暗号化して格納したり、参加者間のインターネット上の仲介行為をスケールすることも可能になります。\n",
            "Human: 2めの要点を300文字程度でまとめてください。\n",
            "AI:\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "answer =conversation.predict_and_parse(input=\"2めの要点を300文字程度でまとめてください。\")\n",
        "res = {\"2\":answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい、ブロックチェーンの専門家として答えます。私はブロックチェーンの基礎技術の導入から開発、テスト、保守までをサポートしています。それぞれのサービスは、堅牢で保証されたブロックチェーン基盤に基づいて開発されており、ビジネス、法律、監査などの技術要件を満たします。また、高速でスケーラブルなソリューションを提供し、あらゆる規模の企業に最適なソリューションを提供しています。\n",
            "Human: web3の3年後の未来はどのようなものですか？\n",
            "AI:  web3の3年後の未来は明確なものではありませんが、利用可能な技術が進んでいることを見込んでいます。主な変化としては、セキュリティとトレーサビリティが大幅に改善され、ブロックチェーンがより広く用いられ、業務プロセスを革新するコラボレーションツールが多数導入されるでしょう。また、データ収集やAIを用いたプロセスの改善など、さらに新しい技術の導入が開発されていくと考えられます。\n",
            "Human: 要点を４つのパートで教えてください。\n",
            "AI:   ブロックチェーンを使用してweb3を改善する要点を４つご紹介します。１つ目は、セキュリティとトレーサビリティが大幅に改善されることです。２つ目は、ブロックチェーンの採用が広がることです。３つ目は、業務プロセスを革新するコラボレーションツールの導入です。そして４つ目は、AIなどの新しい技術の導入です。\n",
            "Human: ひとつめの要点を詳しく300文字程度で教えてください。\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' ひとつ目の要点として、ブロックチェーンによってweb3が改善されるとして、セキュリティとトレーサビリティが大幅に改善されることです。ブロックチェーン技術は、業界標準の技術を使用して、厳格なデータ管理を行い、企業からユーザーまで安全な取引環境を提供します。また、ブロックチェーン技術は、取引の履歴をすべて追跡可能なトランザクションレコードを提供します。これにより、取引に関わる情報や証拠を保存して、組織内で責任を明確にできるようになります。'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer =conversation.predict_and_parse(input=\"3めの要点を300文字程度でまとめてください。\")\n",
        "res = {\"3\":answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい、ブロックチェーンの専門家として答えます。私はブロックチェーンの基礎技術の導入から開発、テスト、保守までをサポートしています。それぞれのサービスは、堅牢で保証されたブロックチェーン基盤に基づいて開発されており、ビジネス、法律、監査などの技術要件を満たします。また、高速でスケーラブルなソリューションを提供し、あらゆる規模の企業に最適なソリューションを提供しています。\n",
            "Human: web3の3年後の未来はどのようなものですか？\n",
            "AI:  web3の3年後の未来は明確なものではありませんが、利用可能な技術が進んでいることを見込んでいます。主な変化としては、セキュリティとトレーサビリティが大幅に改善され、ブロックチェーンがより広く用いられ、業務プロセスを革新するコラボレーションツールが多数導入されるでしょう。また、データ収集やAIを用いたプロセスの改善など、さらに新しい技術の導入が開発されていくと考えられます。\n",
            "Human: 要点を４つのパートで教えてください。\n",
            "AI:   ブロックチェーンを使用してweb3を改善する要点を４つご紹介します。１つ目は、セキュリティとトレーサビリティが大幅に改善されることです。２つ目は、ブロックチェーンの採用が広がることです。３つ目は、業務プロセスを革新するコラボレーションツールの導入です。そして４つ目は、AIなどの新しい技術の導入です。\n",
            "Human: ひとつめの要点を詳しく300文字程度で教えてください。\n",
            "AI:  ひとつ目の要点として、ブロックチェーンによってweb3が改善されるとして、セキュリティとトレーサビリティが大幅に改善されることです。ブロックチェーン技術は、業界標準の技術を使用して、厳格なデータ管理を行い、企業からユーザーまで安全な取引環境を提供します。また、ブロックチェーン技術は、取引の履歴をすべて追跡可能なトランザクションレコードを提供します。これにより、取引に関わる情報や証拠を保存して、組織内で責任を明確にできるようになります。\n",
            "Human: 二つ目の要点を詳しく300文字程度で教えてください。\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' 二つ目の要点として、ブロックチェーン技術の普及は、現在多くの企業が革新的なソリューション開発に必要としているため大きな変革をもたらしています。企業は、取引の監査を簡単に行えるようにするために、ブロックチェーン技術を活用する必要があります。ブロックチェーンを使用することで、取引履歴が正確かつ安全に追跡可能なことを担保できます。さらに、ブロックチェーンを使用した支払いを行う時、企業が保有する暗号通貨を使えばマイナスの信用スコアなしで支払いを行うことが可能となります。'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer =conversation.predict_and_parse(input=\"4めの要点を300文字程度でまとめてください。\")\n",
        "res = {\"4\":answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ブロックチェーンの専門家として答えてください。\n",
            "AI:  はい、ブロックチェーンの専門家として答えます。私はブロックチェーンの基礎技術の導入から開発、テスト、保守までをサポートしています。それぞれのサービスは、堅牢で保証されたブロックチェーン基盤に基づいて開発されており、ビジネス、法律、監査などの技術要件を満たします。また、高速でスケーラブルなソリューションを提供し、あらゆる規模の企業に最適なソリューションを提供しています。\n",
            "Human: web3の3年後の未来はどのようなものですか？\n",
            "AI:  web3の3年後の未来は明確なものではありませんが、利用可能な技術が進んでいることを見込んでいます。主な変化としては、セキュリティとトレーサビリティが大幅に改善され、ブロックチェーンがより広く用いられ、業務プロセスを革新するコラボレーションツールが多数導入されるでしょう。また、データ収集やAIを用いたプロセスの改善など、さらに新しい技術の導入が開発されていくと考えられます。\n",
            "Human: 要点を４つのパートで教えてください。\n",
            "AI:   ブロックチェーンを使用してweb3を改善する要点を４つご紹介します。１つ目は、セキュリティとトレーサビリティが大幅に改善されることです。２つ目は、ブロックチェーンの採用が広がることです。３つ目は、業務プロセスを革新するコラボレーションツールの導入です。そして４つ目は、AIなどの新しい技術の導入です。\n",
            "Human: ひとつめの要点を詳しく300文字程度で教えてください。\n",
            "AI:  ひとつ目の要点として、ブロックチェーンによってweb3が改善されるとして、セキュリティとトレーサビリティが大幅に改善されることです。ブロックチェーン技術は、業界標準の技術を使用して、厳格なデータ管理を行い、企業からユーザーまで安全な取引環境を提供します。また、ブロックチェーン技術は、取引の履歴をすべて追跡可能なトランザクションレコードを提供します。これにより、取引に関わる情報や証拠を保存して、組織内で責任を明確にできるようになります。\n",
            "Human: 二つ目の要点を詳しく300文字程度で教えてください。\n",
            "AI:  二つ目の要点として、ブロックチェーン技術の普及は、現在多くの企業が革新的なソリューション開発に必要としているため大きな変革をもたらしています。企業は、取引の監査を簡単に行えるようにするために、ブロックチェーン技術を活用する必要があります。ブロックチェーンを使用することで、取引履歴が正確かつ安全に追跡可能なことを担保できます。さらに、ブロックチェーンを使用した支払いを行う時、企業が保有する暗号通貨を使えばマイナスの信用スコアなしで支払いを行うことが可能となります。\n",
            "Human: 二つ目の要点の根拠を教えてください。\n",
            "AI:   二つ目の要点の根拠として、ブロックチェーン技術活用によって取引の信頼性と監査可能性が大幅に改善される点があります。取引を行う前後の証拠をコンプライアンス部門が取得、保管、参照できるため機関による確実なセキュリティ確保が可能となります。また、取引関連情報に変更がないことを保証することで、異なる事業間での取引が可能となり、簡素な取引手続きが可能になります。\n",
            "Human: 二つ目の要点の根拠を教えてください。\n",
            "AI:  二つ目の要点の根拠として、ブロックチェーンの技術を用いることで企業は、取引の信頼性と監査可能性を大幅に改善します。ブロックチェーンを用いることで、取引に関わる情報や証拠を正確かつ安全に追跡することが可能となります。また、取引関連情報に変更がないことを保証することで、異なる事業間での取引が可能となり、簡素な取引手続きが可能となります。\n",
            "Human: 二つ目の要点の根拠を教えてください。\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "ename": "InvalidRequestError",
          "evalue": "This model's maximum context length is 4097 tokens, however you requested 4211 tokens (2211 in your prompt; 2000 for the completion). Please reduce your prompt; or completion length.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res\u001b[39m=\u001b[39mconversation\u001b[39m.\u001b[39;49mpredict_and_parse(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m二つ目の要点の根拠を教えてください。\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py:108\u001b[0m, in \u001b[0;36mLLMChain.predict_and_parse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_and_parse\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    107\u001b[0m     \u001b[39m\"\"\"Call predict and then parse the results.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39moutput_parser \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse(result)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py:104\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/base.py:155\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_outputs(outputs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/base.py:152\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    147\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    148\u001b[0m     inputs,\n\u001b[1;32m    149\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    153\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py:88\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m     78\u001b[0m     \u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[1;32m     80\u001b[0m     outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     81\u001b[0m     \u001b[39mfor\u001b[39;00m generation \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mgenerations:\n\u001b[1;32m     82\u001b[0m         \u001b[39m# Get the text of the top generated string.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py:74\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf `stop` is present in any inputs, should be present in all.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         )\n\u001b[1;32m     73\u001b[0m     prompts\u001b[39m.\u001b[39mappend(prompt)\n\u001b[0;32m---> 74\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/llms/base.py:79\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/llms/base.py:76\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     73\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/llms/openai.py:193\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    191\u001b[0m _keys \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcompletion_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtotal_tokens\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    192\u001b[0m \u001b[39mfor\u001b[39;00m _prompts \u001b[39min\u001b[39;00m sub_prompts:\n\u001b[0;32m--> 193\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    194\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    195\u001b[0m     _keys_to_use \u001b[39m=\u001b[39m _keys\u001b[39m.\u001b[39mintersection(response[\u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/llms/openai.py:151\u001b[0m, in \u001b[0;36mBaseOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m@retry\u001b[39m(\n\u001b[1;32m    137\u001b[0m     reraise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m     stop\u001b[39m=\u001b[39mstop_after_attempt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 151\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tenacity/__init__.py:406\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    405\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    408\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tenacity/__init__.py:351\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    349\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m retry_state\u001b[39m.\u001b[39moutcome\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(retry_state\u001b[39m.\u001b[39moutcome\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state\u001b[39m=\u001b[39mretry_state)):\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tenacity/__init__.py:409\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    408\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    410\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    411\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain/llms/openai.py:149\u001b[0m, in \u001b[0;36mBaseOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m@retry\u001b[39m(\n\u001b[1;32m    137\u001b[0m     reraise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m     stop\u001b[39m=\u001b[39mstop_after_attempt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:227\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    207\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    208\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    217\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    218\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    219\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:680\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    678\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    681\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    683\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4211 tokens (2211 in your prompt; 2000 for the completion). Please reduce your prompt; or completion length."
          ]
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "path = './res.json'\n",
        "json_file = open(path, mode=\"w\")\n",
        "json.dump(dict, json_file)\n",
        "json_file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
